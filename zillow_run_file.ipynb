{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import zillow_functions as zl\n",
    "from bs4 import BeautifulSoup\n",
    "from pyvirtualdisplay import Display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of search terms.\n",
    "Function `zipcodes_list()` creates a list of US zip codes that will be passed to the scraper. For example, \n",
    "```\n",
    "st = zipcodes_list(['10', '11', '606'])  \n",
    "```\n",
    "will yield every US zip code that begins with '10', begins with \"11\", or begins with \"606\" as a single list. I recommend using zip codes, as they seem to be the best option for catching as many house listings as possible. If you want to use search terms other than zip codes, simply skip running zipcodes_list() function below, and add a line of code to manually assign values to object `st`, for example:\n",
    "```\n",
    "st = ['Chicago', 'New Haven, CT', '77005', 'Jacksonville, FL']\n",
    "```\n",
    "Keep in mind that, for each search term, the number of listings scraped is capped at 520, so in using a search term like \"Chicago\" the scraper would end up missing most of the results. Param `st_items` can be either a list of zipcode strings, or a single zipcode string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#zipcodes = ['84001','84002','84003','84004','84005','84006','84007','84008','84010','84011','84013','84014','84015','84016','84017','84018','84020', '84021', '84022', '84023', '84024', '84025', '84026', '84027', '84028', '84029', '84031', '84032', '84033', '84034', '84035', '84036', '84037', '84038', '84039', '84040', '84041', '84042', '84043', '84044', '84045', '84046', '84047', '84049', '84050', '84051', '84052', '84053', '84054', '84055', '84056', '84057', '84058', '84059', '84060', '84061', '84062', '84063', '84064', '84065', '84066', '84067', '84068', '84069', '84070', '84071', '84072', '84073', '84074', '84075', '84076', '84078', '84079', '84080', '84082', '84083', '84084', '84085', '84086', '84087', '84088', '84089', '84090', '84091', '84092', '84093', '84094', '84095', '84096', '84097', '84098', '84101', '84102', '84103', '84104', '84105', '84106', '84107', '84108', '84109', '84110', '84111', '84112', '84113', '84114', '84115', '84116', '84117', '84118', '84119', '84120', '84121', '84122', '84123', '84124', '84125', '84126', '84127', '84128', '84130', '84131', '84132', '84133', '84134', '84136', '84138', '84139', '84141', '84143', '84144', '84145', '84147', '84148', '84150', '84151', '84152', '84157', '84158', '84165', '84170', '84171', '84180', '84184', '84189', '84190', '84199', '84201', '84244', '84301', '84302', '84304', '84305', '84306', '84307', '84308', '84309', '84310', '84311', '84312', '84313', '84314', '84315', '84316', '84317', '84318', '84319', '84320', '84321', '84322', '84323', '84324', '84325', '84326', '84327', '84328', '84329', '84330', '84331', '84332', '84333', '84334', '84335', '84336', '84337', '84338', '84339', '84340', '84341', '84401', '84402', '84403', '84404', '84405', '84407', '84408', '84409', '84412', '84414', '84415', '84501', '84510', '84511', '84512', '84513', '84515', '84516', '84518', '84520', '84521', '84522', '84523', '84525', '84526', '84528', '84529', '84530', '84531', '84532', '84533', '84534', '84535', '84536', '84537', '84539', '84540', '84542', '84601', '84602', '84603', '84604', '84605', '84606', '84620', '84621', '84622', '84623', '84624', '84626', '84627', '84628', '84629', '84630', '84631', '84632', '84633', '84634', '84635', '84636', '84637', '84638', '84639', '84640', '84642', '84643', '84644', '84645', '84646', '84647', '84648', '84649', '84651', '84652', '84653', '84654', '84655', '84656', '84657', '84660', '84662', '84663', '84664', '84665', '84667', '84701', '84710', '84711', '84712', '84713', '84714', '84715', '84716', '84718', '84719', '84720', '84721', '84722', '84723', '84724', '84725', '84726', '84728', '84729', '84730', '84731', '84732', '84733', '84734', '84735', '84736', '84737', '84738', '84739', '84740', '84741', '84742', '84743', '84744', '84745', '84746', '84747', '84749', '84750', '84751', '84752', '84753', '84754', '84755', '84756', '84757', '84758', '84759', '84760', '84761', '84762', '84763', '84764', '84765', '84766', '84767', '84770','84771','84772','84773','84774','84775','84776','84779','84780','84781','84782','84783','84784','84790','84791']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = zl.zipcodes_list(st_items = ['84058','84002','84003','84004','84005','84006','84007','84008','84010','84011','84013','84014','84015','84016','84017','84018','84020', '84021', '84022', '84023', '84024', '84025', '84026', '84027', '84028', '84029', '84031', '84032', '84033', '84034', '84035', '84036', '84037', '84038', '84039', '84040', '84041', '84042', '84043', '84044', '84045', '84046', '84047', '84049', '84050', '84051', '84052', '84053', '84054', '84055', '84056', '84057', '84058', '84059', '84060', '84061', '84062', '84063', '84064', '84065', '84066', '84067', '84068', '84069', '84070', '84071', '84072', '84073', '84074', '84075', '84076', '84078', '84079', '84080', '84082', '84083', '84084', '84085', '84086', '84087', '84088', '84089', '84090', '84091', '84092', '84093', '84094', '84095', '84096', '84097', '84098', '84101', '84102', '84103', '84104', '84105', '84106', '84107', '84108', '84109', '84110', '84111', '84112', '84113', '84114', '84115', '84116', '84117', '84118', '84119', '84120', '84121', '84122', '84123', '84124', '84125', '84126', '84127', '84128', '84130', '84131', '84132', '84133', '84134', '84136', '84138', '84139', '84141', '84143', '84144', '84145', '84147', '84148', '84150', '84151', '84152', '84157', '84158', '84165', '84170', '84171', '84180', '84184', '84189', '84190', '84199', '84601', '84602', '84603', '84604', '84605', '84606'])\n",
    "\n",
    "\n",
    "display = Display(visible=0, size=(1200, 900))  \n",
    "display.start()\n",
    "\n",
    "# Initialize the webdriver.\n",
    "driver = zl.init_driver(\"/usr/local/bin/chromedriver\")\n",
    "\n",
    "# Go to www.zillow.com/homes\n",
    "zl.navigate_to_website(driver, \"http://www.zillow.com/homes\")\n",
    "\n",
    "# Click the \"buy\" button.\n",
    "#zl.click_buy_button(driver)\n",
    "\n",
    "# Create 11 variables from the scrapped HTML data.\n",
    "# These variables will make up the final output dataframe.\n",
    "df = pd.DataFrame({'address' : [], \n",
    "                   'bathrooms' : [], \n",
    "                   'bedrooms' : [], \n",
    "                   'city' : [], \n",
    "                   'days_on_zillow' : [], \n",
    "                   'price' : [], \n",
    "                   'sale_type' : [], \n",
    "                   'state' : [], \n",
    "                   'sqft' : [], \n",
    "                   'url' : [], \n",
    "                   'zip' : []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get total number of search terms.\n",
    "num_search_terms = len(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re as re\n",
    "import time\n",
    "import zipcode\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7511e81df167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m search_bar = driver.wait.until(EC.presence_of_element_located(\n\u001b[0;32m----> 2\u001b[0;31m             (By.ID, \"citystatezip\")))\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/zillow/lib/python3.6/site-packages/selenium/webdriver/support/wait.py\u001b[0m in \u001b[0;36muntil\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0muntil_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "search_bar = driver.wait.until(EC.presence_of_element_located(\n",
    "            (By.ID, \"citystatezip\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the scraping.\n",
    "for k in range(num_search_terms):\n",
    "    # Define search term (must be str object).\n",
    "    search_term = st[k]\n",
    "\n",
    "    # Enter search term and execute search.\n",
    "    if zl.enter_search_term(driver, search_term):\n",
    "        print(\"Entering search term number \" + str(k+1) + \n",
    "              \" out of \" + str(num_search_terms))\n",
    "    else:\n",
    "        print(\"Search term \" + str(k+1) + \n",
    "              \" failed, moving onto next search term\\n***\")\n",
    "        continue\n",
    "    \n",
    "    # Check to see if any results were returned from the search.\n",
    "    # If there were none, move onto the next search.\n",
    "    if zl.results_test(driver):\n",
    "        print(\"Search \" + str(search_term) + \n",
    "              \" returned zero results. Moving onto the next search\\n***\")\n",
    "        continue\n",
    "    \n",
    "    # Pull the html for each page of search results. Zillow caps results at \n",
    "    # 20 pages, each page can contain 26 home listings, thus the cap on home \n",
    "    # listings per search is 520.\n",
    "    raw_data = zl.get_html(driver)\n",
    "    print(str(len(raw_data)) + \" pages of listings found\")\n",
    "    \n",
    "    # Take the extracted HTML and split it up by individual home listings.\n",
    "    listings = zl.get_listings(raw_data)\n",
    "    \n",
    "    # For each home listing, extract the 11 variables that will populate that \n",
    "    # specific observation within the output dataframe.\n",
    "    for n in range(len(listings)):\n",
    "        soup = BeautifulSoup(listings[n], \"lxml\")\n",
    "        new_obs = []\n",
    "        \n",
    "        # List that contains number of beds, baths, and total sqft (and \n",
    "        # sometimes price as well).\n",
    "        card_info = zl.get_card_info(soup)\n",
    "        \n",
    "        # Street Address\n",
    "        new_obs.append(zl.get_street_address(soup))\n",
    "        \n",
    "        # Bathrooms\n",
    "        new_obs.append(zl.get_bathrooms(card_info))\n",
    "        \n",
    "        # Bedrooms\n",
    "        new_obs.append(zl.get_bedrooms(card_info))\n",
    "        \n",
    "        # City\n",
    "        new_obs.append(zl.get_city(soup))\n",
    "        \n",
    "        # Days on the Market/Zillow\n",
    "        new_obs.append(zl.get_days_on_market(soup))\n",
    "        \n",
    "        # Price\n",
    "        new_obs.append(zl.get_price(soup, card_info))\n",
    "        \n",
    "        # Sale Type (House for Sale, New Construction, Foreclosure, etc.)\n",
    "        new_obs.append(zl.get_sale_type(soup))\n",
    "        \n",
    "        # Sqft\n",
    "        new_obs.append(zl.get_sqft(card_info))\n",
    "        \n",
    "        # State\n",
    "        new_obs.append(zl.get_state(soup))\n",
    "        \n",
    "        # URL for each house listing\n",
    "        new_obs.append(zl.get_url(soup))\n",
    "        \n",
    "        # Zipcode\n",
    "        new_obs.append(zl.get_zipcode(soup))\n",
    "    \n",
    "        # Append new_obs to df as a new observation\n",
    "        if len(new_obs) == len(df.columns):\n",
    "            df.loc[len(df.index)] = new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close the webdriver connection.\n",
    "zl.close_connection(driver)\n",
    "\n",
    "# Write df to CSV.\n",
    "columns = ['address', 'city', 'state', 'zip', 'price', 'sqft', 'bedrooms', \n",
    "           'bathrooms', 'days_on_zillow', 'sale_type', 'url']\n",
    "df = df[columns]\n",
    "dt = time.strftime(\"%Y-%m-%d\") + \"_\" + time.strftime(\"%H%M%S\")\n",
    "file_name = str(dt) + \".csv\"\n",
    "df.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zillow",
   "language": "python",
   "name": "zillow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
